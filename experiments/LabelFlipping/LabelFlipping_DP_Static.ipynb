{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4CcleTN0SBF"
      },
      "outputs": [],
      "source": [
        "!pip install flexible-fl opacus SciencePlots setuptools flexclash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKNkMlI-0vAq"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from flex.data import Dataset, FedDataDistribution, FedDataset, FedDatasetConfig\n",
        "from flex.model import FlexModel\n",
        "from flex.pool import FlexPool, fed_avg\n",
        "from flex.pool.decorators import (\n",
        "    deploy_server_model,\n",
        "    init_server_model,\n",
        "    set_aggregated_weights,\n",
        "    collect_clients_weights,\n",
        ")\n",
        "from flexclash.data import data_poisoner\n",
        "from flexclash.pool.defences import central_differential_privacy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import scienceplots\n",
        "from typing import List\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import opacus\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from scipy.optimize import linprog\n",
        "import pandas as pd\n",
        "\n",
        "# --- CONSTANTS ---\n",
        "ROUNDS = 100\n",
        "EPOCHS = 1\n",
        "N_CLIENTS = 10\n",
        "POISONED= 1\n",
        "fixed_epsilon = 1.0\n",
        "fixed_delta = 0.001\n",
        "budget = 100.0\n",
        "delta_max = 0.1\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcK0g-KsOIMW"
      },
      "outputs": [],
      "source": [
        "def get_dataset():\n",
        "    \"\"\"\n",
        "    Creation of the Federated MNIST dataset\n",
        "    \"\"\"\n",
        "    train_data = MNIST(root=\".\", train=True, download=True, transform=None)\n",
        "    test_data = MNIST(root=\".\", train=False, download=True, transform=None)\n",
        "    flex_dataset = Dataset.from_torchvision_dataset(train_data)\n",
        "    test_data = Dataset.from_torchvision_dataset(test_data)\n",
        "    assert isinstance(flex_dataset, Dataset)\n",
        "\n",
        "    config = FedDatasetConfig(seed=0)\n",
        "    config.replacement = False\n",
        "    config.n_nodes = N_CLIENTS\n",
        "\n",
        "    flex_dataset = FedDataDistribution.from_config(flex_dataset, config)\n",
        "\n",
        "    assert isinstance(flex_dataset, FedDataset)\n",
        "    flex_dataset[\"server\"] = test_data\n",
        "\n",
        "    return flex_dataset\n",
        "\n",
        "mnist_transforms = transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFdajX3KOIN_"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(1024, 200)\n",
        "        self.fc2 = nn.Linear(200, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.tanh(self.conv1(x)))\n",
        "        x = self.pool(torch.tanh(self.conv2(x)))\n",
        "        x = x.view(-1, 1024)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def get_model(num_classes=10):\n",
        "  return ModuleValidator.fix(CNNModel(num_classes=num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXGrKd1EODvy"
      },
      "outputs": [],
      "source": [
        "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
        "    \"\"\"\n",
        "    Train the model on the client data.\n",
        "    \"\"\"\n",
        "    model = client_flex_model[\"model\"]\n",
        "    criterion = client_flex_model[\"criterion\"]\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    torch_dataset = client_data.to_torchvision_dataset(transform=mnist_transforms)\n",
        "    optimizer = client_flex_model[\"optimizer_func\"](model.parameters(), **client_flex_model[\"optimizer_kwargs\"])\n",
        "    dataloader = DataLoader(\n",
        "        torch_dataset, batch_size=64, shuffle=True, pin_memory=False\n",
        "    )\n",
        "\n",
        "    for _ in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "def evaluate_model(server_flex_model: FlexModel, data):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the server data.\n",
        "    \"\"\"\n",
        "    data = flex_dataset[\"server\"]\n",
        "    model = server_flex_model[\"model\"]\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    total_count = 0\n",
        "    model = model.to(device)\n",
        "    criterion = server_flex_model[\"criterion\"]\n",
        "\n",
        "    test_dataset = data.to_torchvision_dataset(transform=mnist_transforms)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, batch_size=256, shuffle=True, pin_memory=False\n",
        "    )\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            total_count += target.size(0)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            losses.append(criterion(output, target).item())\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
        "\n",
        "    test_loss = sum(losses) / len(losses)\n",
        "    test_acc /= total_count\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu1DLUWkODyK"
      },
      "outputs": [],
      "source": [
        "# FLEX Decorators\n",
        "@init_server_model\n",
        "def build_server_model():\n",
        "    server_flex_model = FlexModel()\n",
        "    server_flex_model[\"model\"] = get_model()\n",
        "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
        "    server_flex_model[\"optimizer_func\"] = torch.optim.SGD\n",
        "    server_flex_model[\"optimizer_kwargs\"] = {\n",
        "        \"lr\": 1e-3,\n",
        "        \"weight_decay\": 1e-7,\n",
        "        \"momentum\": 0,\n",
        "    }\n",
        "    return server_flex_model\n",
        "\n",
        "@deploy_server_model\n",
        "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
        "    new_flex_model = FlexModel()\n",
        "    new_flex_model[\"model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"server_model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"discriminator\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"criterion\"] = copy.deepcopy(server_flex_model[\"criterion\"])\n",
        "    new_flex_model[\"optimizer_func\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_func\"]\n",
        "    )\n",
        "    new_flex_model[\"optimizer_kwargs\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_kwargs\"]\n",
        "    )\n",
        "    return new_flex_model\n",
        "\n",
        "@set_aggregated_weights\n",
        "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
        "    dev = aggregated_weights[0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    with torch.no_grad():\n",
        "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
        "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
        "            weight_dict[layer_key].copy_(weight_dict[layer_key].to(dev) + new)\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_clients_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    server_dict = client_flex_model[\"server_model\"].state_dict()\n",
        "    dev = [weight_dict[name] for name in weight_dict][0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    return [\n",
        "        (weight_dict[name] - server_dict[name].to(dev)).type(torch.float)\n",
        "        for name in weight_dict\n",
        "    ]\n",
        "\n",
        "@data_poisoner\n",
        "def label_flipping(img_array, label, num_classes=10):\n",
        "    \"\"\"Flips the label to a random different class.\"\"\"\n",
        "    while True:\n",
        "        new_label = np.random.randint(0, num_classes)\n",
        "        if new_label != label:\n",
        "            break\n",
        "    return img_array, new_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0T5GHyFOD13"
      },
      "outputs": [],
      "source": [
        "def run_attack_optimize_DP(pool: FlexPool):\n",
        "    \"\"\"\n",
        "    Run the attack and optimize the epsilon and delta parameters. It saves the metrics in a csv file.\n",
        "    \"\"\"\n",
        "\n",
        "    clients = pool.clients\n",
        "    server = pool.servers\n",
        "\n",
        "    epsilon_used = 0\n",
        "    losses = []\n",
        "    accuracies=[]\n",
        "    epsilon_cummulative = []\n",
        "\n",
        "    for i in range(ROUNDS):\n",
        "\n",
        "        print(f\"\\n - Round {i+1}: Aggregating with with ε={fixed_epsilon:.3f}, δ={fixed_delta:.5f}\")\n",
        "        server.map(copy_server_model_to_clients, clients)\n",
        "\n",
        "        epsilon_used += fixed_epsilon\n",
        "        loss = clients.map(train)\n",
        "        losses.append(loss[0])\n",
        "\n",
        "        sensitivity = 0.01\n",
        "        noise_multiplier = (sensitivity / fixed_epsilon) * np.sqrt(2 * np.log(1.25 / fixed_delta))\n",
        "        print(\"Noise multiplier\", noise_multiplier)\n",
        "\n",
        "        pool.servers.map(get_clients_weights, clients)\n",
        "        pool.servers.map(central_differential_privacy, l2_clip = 1.0, noise_multiplier = noise_multiplier)\n",
        "        pool.servers.map(set_agreggated_weights_to_server, pool.servers)\n",
        "\n",
        "        round_metrics = pool.servers.map(evaluate_model)\n",
        "        accuracies.append(round_metrics[0][1]*100)\n",
        "        print(\" * Round metrics: \", round_metrics)\n",
        "        epsilon_cummulative.append(epsilon_used)\n",
        "        print(f\"Epsilon used: {epsilon_used} \\n\")\n",
        "\n",
        "        with open(\"experiment_DP_Static.txt\", \"a\") as archivo:\n",
        "            archivo.write(f\"\\n - Round {i+1}: Training with ε={fixed_epsilon:.3f}, δ={fixed_delta:.5f}\\n\")\n",
        "            archivo.write(f\"Round metrics: {round_metrics}\\n\")\n",
        "            archivo.write(f\"Epsilon used: {epsilon_used}\\n\")\n",
        "            archivo.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "    df_metrics = pd.DataFrame({\n",
        "      'Round': list(range(1, ROUNDS + 1)),\n",
        "      'Accuracy (%)': accuracies,\n",
        "      'Epsilon Acumulado': epsilon_cummulative\n",
        "      })\n",
        "    df_metrics.to_csv('metrics_DP_Static.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufFcliSa4n9U"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    flex_dataset = get_dataset()\n",
        "    poisoned_clients_ids = list(flex_dataset.keys())[:POISONED]\n",
        "    flex_dataset = flex_dataset.apply(label_flipping, node_ids=poisoned_clients_ids)\n",
        "    pool = FlexPool.client_server_pool(\n",
        "        fed_dataset=flex_dataset, init_func=build_server_model\n",
        "    )\n",
        "    run_attack_optimize_DP(pool)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
