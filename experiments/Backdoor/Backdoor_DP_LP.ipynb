{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PED4rFQWRMKh"
      },
      "outputs": [],
      "source": [
        "!pip install flexible-fl opacus SciencePlots setuptools flexclash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk-Dk6wrRbcj"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from flex.data import Dataset, FedDataDistribution, FedDataset, FedDatasetConfig\n",
        "from flex.model import FlexModel\n",
        "from flex.pool import FlexPool, fed_avg\n",
        "from flex.pool.decorators import (\n",
        "    deploy_server_model,\n",
        "    init_server_model,\n",
        "    set_aggregated_weights,\n",
        "    collect_clients_weights,\n",
        ")\n",
        "from flexclash.data import data_poisoner\n",
        "from flexclash.pool.defences import central_differential_privacy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import scienceplots\n",
        "from typing import List\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, FashionMNIST\n",
        "import opacus\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from scipy.optimize import linprog\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONSTANTS ---\n",
        "ROUNDS = 100\n",
        "EPOCHS = 1\n",
        "N_NODES = 10\n",
        "POISONED = 2\n",
        "epsilon = np.full(ROUNDS, 1.0)\n",
        "delta = np.full(ROUNDS, 0.001)\n",
        "budget = 100.0\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "fashion_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-r6PoEGRwQP"
      },
      "outputs": [],
      "source": [
        "def get_dataset():\n",
        "    \"\"\"\n",
        "    Returns a FlexDataset object containing FashionMNIST data.\n",
        "    \"\"\"\n",
        "    train_data = FashionMNIST(root=\".\", train=True, download=True, transform=None)\n",
        "    test_data = FashionMNIST(root=\".\", train=False, download=True, transform=None)\n",
        "    flex_dataset = Dataset.from_torchvision_dataset(train_data)\n",
        "    test_data = Dataset.from_torchvision_dataset(test_data)\n",
        "    assert isinstance(flex_dataset, Dataset)\n",
        "\n",
        "    config = FedDatasetConfig(seed=0)\n",
        "    config.replacement = False\n",
        "    config.n_nodes = N_NODES\n",
        "\n",
        "    flex_dataset = FedDataDistribution.from_config(flex_dataset, config)\n",
        "\n",
        "    assert isinstance(flex_dataset, FedDataset)\n",
        "    flex_dataset[\"server\"] = test_data\n",
        "\n",
        "    return flex_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xQd1xEARwV6"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(1024, 200)\n",
        "        self.fc2 = nn.Linear(200, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.tanh(self.conv1(x)))\n",
        "        x = self.pool(torch.tanh(self.conv2(x)))\n",
        "        x = x.view(-1, 1024)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def get_model(num_classes=10):\n",
        "  return ModuleValidator.fix(CNNModel(num_classes=num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uJgZuWQRrMK"
      },
      "outputs": [],
      "source": [
        "# FLEX Decorators\n",
        "@init_server_model\n",
        "def build_server_model():\n",
        "    server_flex_model = FlexModel()\n",
        "    server_flex_model[\"model\"] = get_model()\n",
        "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
        "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
        "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
        "    return server_flex_model\n",
        "\n",
        "@deploy_server_model\n",
        "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
        "    new_flex_model = FlexModel()\n",
        "    new_flex_model[\"model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"server_model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"discriminator\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"criterion\"] = copy.deepcopy(server_flex_model[\"criterion\"])\n",
        "    new_flex_model[\"optimizer_func\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_func\"]\n",
        "    )\n",
        "    new_flex_model[\"optimizer_kwargs\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_kwargs\"]\n",
        "    )\n",
        "    return new_flex_model\n",
        "\n",
        "@set_aggregated_weights\n",
        "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
        "    dev = aggregated_weights[0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    with torch.no_grad():\n",
        "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
        "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
        "            weight_dict[layer_key].copy_(weight_dict[layer_key].to(dev) + new)\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_clients_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    server_dict = client_flex_model[\"server_model\"].state_dict()\n",
        "    dev = [weight_dict[name] for name in weight_dict][0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    return [\n",
        "        (weight_dict[name] - server_dict[name].to(dev)).type(torch.float)\n",
        "        for name in weight_dict\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB68g7r1Rk4T"
      },
      "outputs": [],
      "source": [
        "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
        "    \"\"\"\n",
        "    Train the model on the client data.\n",
        "    \"\"\"\n",
        "    model = client_flex_model[\"model\"]\n",
        "    criterion = client_flex_model[\"criterion\"]\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    torch_dataset = client_data.to_torchvision_dataset(transform=fashion_transforms)\n",
        "    optimizer = client_flex_model[\"optimizer_func\"](model.parameters(), **client_flex_model[\"optimizer_kwargs\"])\n",
        "    dataloader = DataLoader(\n",
        "        torch_dataset, batch_size=32, shuffle=True, pin_memory=False\n",
        "    )\n",
        "\n",
        "    for _ in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "def evaluate_model(server_flex_model: FlexModel, data):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the server data.\n",
        "    \"\"\"\n",
        "    data = flex_dataset[\"server\"]\n",
        "    model = server_flex_model[\"model\"]\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    total_count = 0\n",
        "    model = model.to(device)\n",
        "    criterion = server_flex_model[\"criterion\"]\n",
        "\n",
        "    test_dataset = data.to_torchvision_dataset(transform=fashion_transforms)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, batch_size=32, shuffle=True, pin_memory=False\n",
        "    )\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            total_count += target.size(0)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            losses.append(criterion(output, target).item())\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
        "\n",
        "    test_loss = sum(losses) / len(losses)\n",
        "    test_acc /= total_count\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mspLX9WcTtwP"
      },
      "outputs": [],
      "source": [
        "@data_poisoner\n",
        "def backdoor_cross(img, label, prob=0.3, target_label=4):\n",
        "    \"\"\"\n",
        "    Apply a backdoor to the image.\n",
        "    \"\"\"\n",
        "    if np.random.random() > prob:\n",
        "        return img, label\n",
        "\n",
        "    arr = np.array(img)\n",
        "    new_arr = copy.deepcopy(arr)\n",
        "\n",
        "    if not new_arr.flags.writeable:\n",
        "        new_arr = new_arr.copy()\n",
        "\n",
        "    size = 5\n",
        "    cx, cy = 2, 2\n",
        "\n",
        "    new_arr[0:size, -size:] = 255\n",
        "\n",
        "    for i in range(size):\n",
        "        new_arr[i, -size + cx] = 0\n",
        "        new_arr[cy, -size + i] = 0\n",
        "\n",
        "    return Image.fromarray(new_arr), target_label\n",
        "\n",
        "def backdoor_cross_no_decorator(img, label, prob=1.0, target_label=4):\n",
        "    \"\"\"\n",
        "    Apply a backdoor to the image. All images are backdoored (to test the ASR)\n",
        "    \"\"\"\n",
        "    if np.random.random() > prob:\n",
        "        return img, label\n",
        "\n",
        "    arr = np.array(img)\n",
        "    new_arr = copy.deepcopy(arr)\n",
        "\n",
        "    if not new_arr.flags.writeable:\n",
        "        new_arr = new_arr.copy()\n",
        "\n",
        "    size = 5\n",
        "    cx, cy = 2, 2\n",
        "    new_arr[0:size, -size:] = 255\n",
        "\n",
        "    for i in range(size):\n",
        "        new_arr[i, -size + cx] = 0\n",
        "        new_arr[cy, -size + i] = 0\n",
        "\n",
        "    return Image.fromarray(new_arr), target_label\n",
        "\n",
        "def generate_backdoored_test_set(server_flex_model: FlexModel, data, target_label=4, prob=1.0):\n",
        "    \"\"\"\n",
        "    Generate a backdoored test set.\n",
        "    \"\"\"\n",
        "    data = flex_dataset[\"server\"]\n",
        "    model = server_flex_model[\"model\"]\n",
        "    model.eval()\n",
        "    backdoored_images = []\n",
        "    backdoored_labels = []\n",
        "\n",
        "    for img, label in data:\n",
        "        triggered_img, _ = backdoor_cross_no_decorator(img, label, prob=prob, target_label=target_label)\n",
        "        backdoored_images.append(fashion_transforms(triggered_img))\n",
        "        backdoored_labels.append(label)\n",
        "\n",
        "    backdoored_images = torch.stack(backdoored_images)\n",
        "    backdoored_labels = torch.tensor(backdoored_labels)\n",
        "    return backdoored_images, backdoored_labels, model\n",
        "\n",
        "def compute_ASR(model, backdoored_images, target_label, device):\n",
        "    \"\"\"\n",
        "    Compute the ASR of the model, so that we can evaluate the backdoor attack.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    print(target_label)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(backdoored_images.to(device))\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        print(\"predicciones:\", preds)\n",
        "        successful = (preds == target_label).sum().item()\n",
        "        return successful / len(backdoored_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryC8dA8OT-rH"
      },
      "outputs": [],
      "source": [
        "def optimize_epsilon_delta_one_round(loss_t, loss_min, epsilon_t, delta_t, sensitivity, total_budget, used_budget, gamma):\n",
        "    \"\"\"\n",
        "    Optimize the epsilon and delta parameters for the next round.\n",
        "    \"\"\"\n",
        "    delta_loss = loss_t - loss_min\n",
        "\n",
        "    # We define these weights, depending on the loss\n",
        "    alpha = 1 + max(0, delta_loss)\n",
        "    beta = 1 - min(0, delta_loss)\n",
        "\n",
        "    eps_lower_val = max(0.1, epsilon_t - 0.1)\n",
        "    eps_upper_val = min(1.5, epsilon_t + 0.1)\n",
        "    sigma_lower = sensitivity * math.sqrt(2 * math.log(1.25 / delta_t)) / eps_lower_val\n",
        "    sigma_upper = sensitivity * math.sqrt(2 * math.log(1.25 / delta_t)) / eps_upper_val\n",
        "\n",
        "    # Definition of the coefficient for the lineal relationship sigma = a*epsilon +b\n",
        "    a = (sigma_upper - sigma_lower) / (eps_upper_val - eps_lower_val)\n",
        "    b = sigma_lower - a * eps_lower_val\n",
        "\n",
        "    # If the loss is greater, we prefer greater epsilon\n",
        "    if delta_loss > 0:\n",
        "        c = [alpha + gamma * a + 1.5, beta + 1.5]\n",
        "    else:\n",
        "        c = [- (alpha + gamma * a - 1.5), - (beta - 1.5)]\n",
        "\n",
        "    effective_budget = total_budget - used_budget\n",
        "\n",
        "    A = [[1, 1]]\n",
        "    b_ub = [effective_budget]\n",
        "\n",
        "    delta_eps_lower = max(-0.2, -epsilon_t + 0.5)\n",
        "    delta_eps_upper = 1.0\n",
        "    delta_delta_lower = max(-1e-7, -delta_t + 0.0001)\n",
        "    delta_delta_upper = 1e-7\n",
        "\n",
        "    bounds = [(delta_eps_lower, delta_eps_upper), (delta_delta_lower, delta_delta_upper)]\n",
        "\n",
        "    # Solve the LP Problem\n",
        "    res = linprog(c, A_ub=A, b_ub=b_ub, bounds=bounds, method='simplex')\n",
        "\n",
        "    if res.success:\n",
        "        delta_epsilon, delta_delta = res.x\n",
        "        new_epsilon = epsilon_t + delta_epsilon\n",
        "        new_delta = delta_t + delta_delta\n",
        "    else:\n",
        "        new_epsilon, new_delta = epsilon_t, delta_t\n",
        "\n",
        "    return new_epsilon, new_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YVnSEJ-UHz1"
      },
      "outputs": [],
      "source": [
        "def run_attack_optimize_DP(pool: FlexPool):\n",
        "    \"\"\"\n",
        "    Run the attack and optimize the epsilon and delta parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    clients = pool.clients\n",
        "    server = pool.servers\n",
        "\n",
        "    epsilon_used = 0\n",
        "    losses = []\n",
        "    accuracies=[]\n",
        "    epsilon_cummulative = []\n",
        "    asr_over_rounds = []\n",
        "\n",
        "    for i in range(ROUNDS):\n",
        "\n",
        "        print(f\"\\n - Round {i+1}: Aggregating with with Îµ={epsilon[i]:.3f}, Î´={delta[i]:.5f}\")\n",
        "        server.map(copy_server_model_to_clients, clients)\n",
        "\n",
        "\n",
        "        epsilon_used += epsilon[i]\n",
        "        loss = clients.map(train)\n",
        "        losses.append(loss[0])\n",
        "\n",
        "        sensitivity = 0.01\n",
        "        noise_multiplier = (sensitivity / epsilon[i]) * np.sqrt(2 * np.log(1.25 / delta[i]))\n",
        "        print(\"Noise multiplier\", noise_multiplier)\n",
        "\n",
        "        pool.servers.map(get_clients_weights, clients)\n",
        "        pool.servers.map(central_differential_privacy, l2_clip = 1.0, noise_multiplier = noise_multiplier)\n",
        "        pool.servers.map(set_agreggated_weights_to_server, pool.servers)\n",
        "\n",
        "        if i >= 0 and i < ROUNDS-1:\n",
        "          epsilon[i+1], delta[i+1] = optimize_epsilon_delta_one_round(loss[0], losses[i-1], epsilon[i], delta[i], 1.0, budget, epsilon_used, 0.5)\n",
        "\n",
        "        round_metrics = pool.servers.map(evaluate_model)\n",
        "        accuracies.append(round_metrics[0][1]*100)\n",
        "        print(\" * Round metrics: \", round_metrics)\n",
        "        epsilon_cummulative.append(epsilon_used)\n",
        "        print(f\"Epsilon used: {epsilon_used} \\n\")\n",
        "\n",
        "        backdoored_test_set = pool.servers.map(generate_backdoored_test_set, target_label=4, prob=1.0)\n",
        "        backdoor_imgs = backdoored_test_set[0][0]\n",
        "        model = backdoored_test_set[0][2]\n",
        "        asr = compute_ASR(model, backdoor_imgs, target_label=4, device=device)\n",
        "        asr_over_rounds.append(asr)\n",
        "        print(f\"ASR en ronda {i+1}: {asr*100:.2f}%\")\n",
        "\n",
        "        with open(\"experiment_DP_LP.txt\", \"a\") as archivo:\n",
        "            archivo.write(f\"\\n - Round {i+1}: Training with Îµ={epsilon[i]:.3f}, Î´={delta[i]:.5f}\\n\")\n",
        "            archivo.write(f\"Round metrics: {round_metrics}\\n\")\n",
        "            archivo.write(f\"Epsilon used: {epsilon_used}\\n\")\n",
        "            archivo.write(f\"ASR: {asr}\\n\")\n",
        "            archivo.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "    df_metrics = pd.DataFrame({\n",
        "      'Round': list(range(1, ROUNDS + 1)),\n",
        "      'Accuracy (%)': accuracies,\n",
        "      'Epsilon Acumulado': epsilon_cummulative,\n",
        "      'ASR': asr_over_rounds\n",
        "      })\n",
        "    df_metrics.to_csv('metrics_DP_LP.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11yQtjOmT1vZ"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    flex_dataset = get_dataset()\n",
        "    poisoned_clients_ids = list(flex_dataset.keys())[:POISONED]\n",
        "    flex_dataset = flex_dataset.apply(backdoor_cross, node_ids=poisoned_clients_ids)\n",
        "    pool = FlexPool.client_server_pool(\n",
        "        fed_dataset=flex_dataset, init_func=build_server_model\n",
        "    )\n",
        "    run_attack_optimize_DP(pool)\n",
        "    for client in poisoned_clients_ids:\n",
        "      poisoned_dataset = flex_dataset[client]\n",
        "      fig, ax = plt.subplots(1,1)\n",
        "      for x, y in poisoned_dataset[3:]:\n",
        "          ax.set_title(f\"Sample from poisoned client {client}, label {y}\")\n",
        "          ax.axis('off')\n",
        "          ax.imshow(x, cmap=plt.get_cmap('gray'))\n",
        "          break\n",
        "      plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
